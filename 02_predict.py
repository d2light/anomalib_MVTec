from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, classification_report
import torch
import json

from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.models import EfficientAd
from anomalib.metrics import AUROC, F1Score, Evaluator
from torchvision.transforms.v2 import Resize

# PyTorch 2.6+ í˜¸í™˜ì„±: PreProcessor í´ë˜ìŠ¤ë¥¼ ì•ˆì „í•œ ê¸€ë¡œë²Œë¡œ ì¶”ê°€
from anomalib.pre_processing.pre_processor import PreProcessor
torch.serialization.add_safe_globals([PreProcessor])

print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!")

# ============================================
# 1. ì„¤ì •
# ============================================
DATA_ROOT = "./datasets/MVTecAD/capsule"
CATEGORY = "capsule"
RESULTS_DIR = "./results"
OUTPUT_DIR = "./predictions"

# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸° (ê°€ì¥ ìµœì‹  ë²„ì „)
results_path = Path(RESULTS_DIR) / "EfficientAd" / CATEGORY
if results_path.exists():
    # v0, v1, v2... ì¤‘ ê°€ì¥ ìµœì‹  ë²„ì „ ì°¾ê¸°
    versions = [d for d in results_path.iterdir() if d.is_dir() and d.name.startswith('v')]
    if versions:
        latest_version = max(versions, key=lambda x: int(x.name[1:]) if x.name[1:].isdigit() else 0)
        ckpt_path = latest_version / "weights" / "lightning" / "model.ckpt"
        if not ckpt_path.exists():
            # ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„
            ckpt_path = list(latest_version.glob("**/model.ckpt"))
            if ckpt_path:
                ckpt_path = ckpt_path[0]
            else:
                raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}")
    else:
        raise FileNotFoundError(f"ë²„ì „ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}")
else:
    raise FileNotFoundError(f"ê²°ê³¼ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {results_path}")

print(f"ğŸ“ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ: {ckpt_path}")

# ============================================
# 1-1. Threshold ì •ë³´ ë¡œë“œ (ëª¨ë¸ ì €ì¥ ê²½ë¡œì—ì„œ)
# ============================================
threshold_info = None
threshold_json_path = ckpt_path.parent.parent / "threshold_info.json"
if not threshold_json_path.exists():
    # ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„ (ì²´í¬í¬ì¸íŠ¸ì™€ ê°™ì€ ë””ë ‰í† ë¦¬)
    threshold_json_path = ckpt_path.parent / "threshold_info.json"
    if not threshold_json_path.exists():
        # ë²„ì „ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
        version_dir = ckpt_path.parent.parent.parent if "weights" in str(ckpt_path) else ckpt_path.parent.parent
        threshold_json_path = version_dir / "threshold_info.json"

if threshold_json_path.exists():
    with open(threshold_json_path, "r", encoding="utf-8") as f:
        threshold_info = json.load(f)
    print(f"âœ… Threshold ì •ë³´ ë¡œë“œ: {threshold_json_path}")
    print(f"   - Best Threshold: {threshold_info.get('best_threshold', 'N/A')}")
    print(f"   - Good Threshold: {threshold_info.get('good_threshold', 'N/A')}")
    print(f"   - Bad Threshold: {threshold_info.get('bad_threshold', 'N/A')}")
else:
    print(f"âš ï¸ Threshold ì •ë³´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {threshold_json_path}")
    print(f"   ëª¨ë¸ ë‚´ë¶€ threshold ì •ë³´ë¥¼ í™•ì¸í•©ë‹ˆë‹¤...")

# ============================================
# 2. ë°ì´í„°ì…‹ ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)
# ============================================
resize_transform = Resize(size=(256, 256))

datamodule = Folder(
    name=CATEGORY,
    root=DATA_ROOT,
    normal_dir="train/good",
    abnormal_dir=[
        "test/crack",
        "test/faulty_imprint",
        "test/poke",
        "test/scratch",
        "test/squeeze",
    ],
    normal_test_dir="test/good",
    train_batch_size=1,
    eval_batch_size=1,
    num_workers=0,
    augmentations=resize_transform,
)

datamodule.setup()
print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!")

# ============================================
# 3. ëª¨ë¸ ë° ì—”ì§„ ì„¤ì •
# ============================================
# í‰ê°€ ì§€í‘œ ì„¤ì •
test_metrics = [
    AUROC(fields=["pred_score", "gt_label"], prefix="image_"),
    F1Score(fields=["pred_label", "gt_label"], prefix="image_"),
]
evaluator = Evaluator(test_metrics=test_metrics)

pre_processor = EfficientAd.configure_pre_processor(image_size=(256, 256))

model = EfficientAd(
    teacher_out_channels=384,
    model_size="small",
    lr=0.0001,
    weight_decay=0.00001,
    padding=False,
    pad_maps=True,
    evaluator=evaluator,
    pre_processor=pre_processor,
)

engine = Engine(
    accelerator="auto",
    devices=1,
)

print("âœ… ëª¨ë¸ ë° ì—”ì§„ ì„¤ì • ì™„ë£Œ!")

# ============================================
# 4. ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë“œ
# ============================================
print(f"ğŸ“¦ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ê°€ì¤‘ì¹˜ ë¡œë“œ ì¤‘: {ckpt_path}")


try:
    checkpoint = torch.load(str(ckpt_path), map_location='cpu', weights_only=False)
except TypeError:
    checkpoint = torch.load(str(ckpt_path), map_location='cpu', weights_only=True)

# PyTorch Lightning ì²´í¬í¬ì¸íŠ¸ì—ì„œ state_dict ì¶”ì¶œ
if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:
    state_dict = checkpoint['state_dict']
    # PyTorch Lightningì€ 'model.' prefixë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì œê±°
    state_dict = {k.replace('model.', '') if k.startswith('model.') else k: v 
                  for k, v in state_dict.items()}
elif isinstance(checkpoint, dict):
    # state_dictê°€ ì§ì ‘ ìˆëŠ” ê²½ìš°
    state_dict = checkpoint
else:
    raise ValueError(f"ì²´í¬í¬ì¸íŠ¸ í˜•ì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {type(checkpoint)}")

# ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ
missing_keys, unexpected_keys = model.load_state_dict(state_dict, strict=False)
if missing_keys:
    print(f"âš ï¸ ëˆ„ë½ëœ í‚¤: {len(missing_keys)}ê°œ (ì¼ë¶€ëŠ” ì •ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
if unexpected_keys:
    print(f"âš ï¸ ì˜ˆìƒì¹˜ ëª»í•œ í‚¤: {len(unexpected_keys)}ê°œ")

model.eval()

print("âœ… ê°€ì¤‘ì¹˜ ë¡œë“œ ì™„ë£Œ!")

# ============================================
# ëª¨ë¸ ë‚´ë¶€ threshold ì •ë³´ í™•ì¸ (JSON ìš°ì„ , ì—†ìœ¼ë©´ ëª¨ë¸ ë‚´ë¶€)
# ============================================
print("\n" + "="*60)
print("ğŸ“Š Threshold ì •ë³´ í™•ì¸")
print("="*60)

# JSONì—ì„œ ì½ì€ threshold ì •ë³´ ìš°ì„  ì‚¬ìš©
if threshold_info:
    best_threshold = threshold_info.get('best_threshold')
    good_threshold = threshold_info.get('good_threshold')
    bad_threshold = threshold_info.get('bad_threshold')
    threshold_accuracy = threshold_info.get('threshold_accuracy')
    threshold_auc = threshold_info.get('threshold_auc')
    threshold_category = threshold_info.get('category')
    
    print("ğŸ“„ Threshold ì •ë³´ ì¶œì²˜: JSON íŒŒì¼")
    if best_threshold is not None:
        print(f"âœ… Best Threshold: {best_threshold:.6f}")
    else:
        print("âŒ Best Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if good_threshold is not None and good_threshold > 0:
        print(f"âœ… Good Threshold: {good_threshold:.6f}")
    elif good_threshold is not None:
        print(f"âš ï¸ Good Threshold: {good_threshold:.6f} (ì„¤ì •ë˜ì§€ ì•ŠìŒ)")
    else:
        print("âŒ Good Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if bad_threshold is not None and bad_threshold > 0:
        print(f"âœ… Bad Threshold: {bad_threshold:.6f}")
    elif bad_threshold is not None:
        print(f"âš ï¸ Bad Threshold: {bad_threshold:.6f} (ì„¤ì •ë˜ì§€ ì•ŠìŒ)")
    else:
        print("âŒ Bad Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if threshold_accuracy is not None:
        print(f"ğŸ“ˆ Threshold Accuracy: {threshold_accuracy:.2f}%")
    if threshold_auc is not None:
        print(f"ğŸ“ˆ Threshold AUROC: {threshold_auc:.2f}%")
    if threshold_category:
        print(f"ğŸ“¦ Category: {threshold_category}")
else:
    # JSONì´ ì—†ìœ¼ë©´ ëª¨ë¸ ë‚´ë¶€ threshold í™•ì¸
    print("ğŸ“„ Threshold ì •ë³´ ì¶œì²˜: ëª¨ë¸ ë‚´ë¶€")
    
    if hasattr(model, 'best_threshold'):
        best_threshold = model.best_threshold.item()
        print(f"âœ… Best Threshold: {best_threshold:.6f}")
    else:
        best_threshold = None
        print("âŒ Best Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if hasattr(model, 'good_threshold'):
        good_threshold = model.good_threshold.item()
        if good_threshold > 0:
            print(f"âœ… Good Threshold: {good_threshold:.6f}")
        else:
            print(f"âš ï¸ Good Threshold: {good_threshold:.6f} (ì„¤ì •ë˜ì§€ ì•ŠìŒ)")
    else:
        good_threshold = None
        print("âŒ Good Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if hasattr(model, 'bad_threshold'):
        bad_threshold = model.bad_threshold.item()
        if bad_threshold > 0:
            print(f"âœ… Bad Threshold: {bad_threshold:.6f}")
        else:
            print(f"âš ï¸ Bad Threshold: {bad_threshold:.6f} (ì„¤ì •ë˜ì§€ ì•ŠìŒ)")
    else:
        bad_threshold = None
        print("âŒ Bad Threshold: ì €ì¥ë˜ì§€ ì•ŠìŒ")
    
    if hasattr(model, 'threshold_accuracy'):
        threshold_accuracy = model.threshold_accuracy
        print(f"ğŸ“ˆ Threshold Accuracy: {threshold_accuracy:.2f}%")
    if hasattr(model, 'threshold_auc'):
        threshold_auc = model.threshold_auc
        print(f"ğŸ“ˆ Threshold AUROC: {threshold_auc:.2f}%")
    if hasattr(model, 'threshold_category'):
        threshold_category = model.threshold_category
        print(f"ğŸ“¦ Category: {threshold_category}")

print("="*60)

# Threshold ì‚¬ìš© ì•ˆë‚´
if best_threshold is not None:
    print(f"\nğŸ’¡ ì˜ˆì¸¡ ì‹œ Threshold ì‚¬ìš© ë°©ë²•:")
    print(f"   - Best Threshold ({best_threshold:.6f})ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ë ˆì´ë¸” ê²°ì •")
    print(f"   - anomalib ê·œì¹™: ì–‘í’ˆ=0, ë¶ˆëŸ‰=1, ë†’ì€ score=ë¹„ì •ìƒ")
    print(f"   - pred_score >= {best_threshold:.6f} â†’ ë¹„ì •ìƒ (1)")
    print(f"   - pred_score < {best_threshold:.6f} â†’ ì •ìƒ (0)")
    if good_threshold is not None and good_threshold > 0:
        print(f"   - Good Threshold: {good_threshold:.6f}")
    if bad_threshold is not None and bad_threshold > 0:
        print(f"   - Bad Threshold: {bad_threshold:.6f}")
else:
    print(f"\nâš ï¸ Threshold ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ í•™ìŠµ ì‹œ thresholdë¥¼ ì €ì¥í•˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    print(f"   ì˜ˆì¸¡ ì‹œ ê¸°ë³¸ thresholdë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

print()

# ============================================
# 5. ì˜ˆì¸¡ ìˆ˜í–‰
# ============================================
print("ğŸ” ì˜ˆì¸¡ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
predictions = engine.predict(
    model=model,
    datamodule=datamodule,
)

print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ì´ {len(predictions)} ë°°ì¹˜")

# ============================================
# 6. ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
# ============================================
results = []

for batch in predictions:
    batch_size = batch.image.shape[0]
    
    for i in range(batch_size):
        # ì´ë¯¸ì§€ ê²½ë¡œ
        image_path = batch.image_path[i] if hasattr(batch, 'image_path') else f"unknown_{i}"
        
        # ì‹¤ì œ ë ˆì´ë¸” (0: ì •ìƒ, 1: ë¹„ì •ìƒ)
        gt_label = batch.gt_label[i].item() if hasattr(batch, 'gt_label') else None
        
        # ì˜ˆì¸¡ ë ˆì´ë¸” (0: ì •ìƒ, 1: ë¹„ì •ìƒ)
        pred_label = batch.pred_label[i].item() if hasattr(batch, 'pred_label') else None
        
        # ì˜ˆì¸¡ ì ìˆ˜
        pred_score = batch.pred_score[i].item() if hasattr(batch, 'pred_score') else None
        
        # ë ˆì´ë¸”ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        gt_label_text = "ì •ìƒ" if gt_label == 0 else "ë¹„ì •ìƒ"
        pred_label_text = "ì •ìƒ" if pred_label == 0 else "ë¹„ì •ìƒ"
        
        # Threshold ì •ë³´ ì¶”ê°€
        result_dict = {
            "image_path": str(image_path),
            "gt_label": gt_label,
            "gt_label_text": gt_label_text,
            "pred_label": pred_label,
            "pred_label_text": pred_label_text,
            "pred_score": pred_score,
            "correct": gt_label == pred_label if gt_label is not None and pred_label is not None else None,
        }
        
        # Threshold ì •ë³´ ì¶”ê°€ (ìˆëŠ” ê²½ìš°)
        if best_threshold is not None:
            result_dict["best_threshold"] = best_threshold
            result_dict["threshold_ê¸°ì¤€_ì˜ˆì¸¡"] = "ì •ìƒ" if pred_score >= best_threshold else "ë¹„ì •ìƒ"
            result_dict["score_vs_threshold"] = pred_score - best_threshold if pred_score is not None else None
        if good_threshold is not None and good_threshold > 0:
            result_dict["good_threshold"] = good_threshold
        if bad_threshold is not None and bad_threshold > 0:
            result_dict["bad_threshold"] = bad_threshold
        
        results.append(result_dict)

# DataFrame ìƒì„±
df = pd.DataFrame(results)

print(f"\nğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½:")
print(f"  - ì´ ì´ë¯¸ì§€ ìˆ˜: {len(df)}")
print(f"  - ì •í™•ë„: {df['correct'].sum() / len(df) * 100:.2f}%")
print(f"  - ì •ìƒ ì´ë¯¸ì§€: {(df['gt_label'] == 0).sum()}ê°œ")
print(f"  - ë¹„ì •ìƒ ì´ë¯¸ì§€: {(df['gt_label'] == 1).sum()}ê°œ")

# Threshold ì •ë³´ í‘œì‹œ
if best_threshold is not None:
    print(f"\nğŸ“Š ì‚¬ìš©ëœ Threshold:")
    print(f"  - Best Threshold: {best_threshold:.6f}")
    if good_threshold is not None and good_threshold > 0:
        print(f"  - Good Threshold: {good_threshold:.6f}")
    if bad_threshold is not None and bad_threshold > 0:
        print(f"  - Bad Threshold: {bad_threshold:.6f}")
    
    # Threshold ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ëœ ì´ë¯¸ì§€ ìˆ˜
    threshold_based_normal = (df['pred_score'] >= best_threshold).sum()
    threshold_based_abnormal = (df['pred_score'] < best_threshold).sum()
    print(f"  - Threshold ê¸°ì¤€ ì •ìƒ ì˜ˆì¸¡: {threshold_based_normal}ê°œ")
    print(f"  - Threshold ê¸°ì¤€ ë¹„ì •ìƒ ì˜ˆì¸¡: {threshold_based_abnormal}ê°œ")

# ============================================
# 7. Confusion Matrix ìƒì„±
# ============================================
if df['gt_label'].notna().all() and df['pred_label'].notna().all():
    # Confusion Matrix ê³„ì‚°
    cm = confusion_matrix(df['gt_label'], df['pred_label'], labels=[0, 1])
    
    # ì‹œê°í™”
    plt.figure(figsize=(8, 6))
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=['ì •ìƒ', 'ë¹„ì •ìƒ'],
        yticklabels=['ì •ìƒ', 'ë¹„ì •ìƒ'],
        cbar_kws={'label': 'ê°œìˆ˜'}
    )
    plt.title('Confusion Matrix', fontsize=14, fontweight='bold')
    plt.ylabel('ì‹¤ì œ ë ˆì´ë¸”', fontsize=12)
    plt.xlabel('ì˜ˆì¸¡ ë ˆì´ë¸”', fontsize=12)
    plt.tight_layout()
    
    # ì €ì¥
    output_path = Path(OUTPUT_DIR)
    output_path.mkdir(exist_ok=True)
    plt.savefig(output_path / 'confusion_matrix.png', dpi=300, bbox_inches='tight')
    print(f"âœ… Confusion Matrix ì €ì¥: {output_path / 'confusion_matrix.png'}")
    plt.close()
    
    # Classification Report
    report = classification_report(
        df['gt_label'],
        df['pred_label'],
        target_names=['ì •ìƒ', 'ë¹„ì •ìƒ'],
        output_dict=True
    )
    
    report_df = pd.DataFrame(report).transpose()
    report_df.to_csv(output_path / 'classification_report.csv', encoding='utf-8-sig')
    print(f"âœ… Classification Report ì €ì¥: {output_path / 'classification_report.csv'}")
    
    print("\nğŸ“ˆ Classification Report:")
    print(classification_report(
        df['gt_label'],
        df['pred_label'],
        target_names=['ì •ìƒ', 'ë¹„ì •ìƒ']
    ))

# ============================================
# 8. CSV íŒŒì¼ë¡œ ì €ì¥
# ============================================
output_path = Path(OUTPUT_DIR)
output_path.mkdir(exist_ok=True)

# ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥
csv_path = output_path / 'predictions.csv'
df.to_csv(csv_path, index=False, encoding='utf-8-sig')
print(f"\nâœ… ì˜ˆì¸¡ ê²°ê³¼ CSV ì €ì¥: {csv_path}")

# ìš”ì•½ í†µê³„ ì €ì¥
summary = {
    "ì´ ì´ë¯¸ì§€ ìˆ˜": len(df),
    "ì •í™•ë„ (%)": f"{df['correct'].sum() / len(df) * 100:.2f}",
    "ì •ìƒ ì´ë¯¸ì§€ ìˆ˜": int((df['gt_label'] == 0).sum()),
    "ë¹„ì •ìƒ ì´ë¯¸ì§€ ìˆ˜": int((df['gt_label'] == 1).sum()),
    "ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡": int((df['pred_label'] == 0).sum()),
    "ë¹„ì •ìƒìœ¼ë¡œ ì˜ˆì¸¡": int((df['pred_label'] == 1).sum()),
    "í‰ê·  ì˜ˆì¸¡ ì ìˆ˜": f"{df['pred_score'].mean():.4f}",
    "ìµœì†Œ ì˜ˆì¸¡ ì ìˆ˜": f"{df['pred_score'].min():.4f}",
    "ìµœëŒ€ ì˜ˆì¸¡ ì ìˆ˜": f"{df['pred_score'].max():.4f}",
}

# Threshold ì •ë³´ ì¶”ê°€
if best_threshold is not None:
    summary["best_threshold"] = f"{best_threshold:.6f}"
    if good_threshold is not None and good_threshold > 0:
        summary["good_threshold"] = f"{good_threshold:.6f}"
    if bad_threshold is not None and bad_threshold > 0:
        summary["bad_threshold"] = f"{bad_threshold:.6f}"
    
    # Threshold ê¸°ì¤€ í†µê³„
    threshold_based_normal = (df['pred_score'] >= best_threshold).sum()
    threshold_based_abnormal = (df['pred_score'] < best_threshold).sum()
    summary["threshold_ê¸°ì¤€_ì •ìƒ_ì˜ˆì¸¡"] = int(threshold_based_normal)
    summary["threshold_ê¸°ì¤€_ë¹„ì •ìƒ_ì˜ˆì¸¡"] = int(threshold_based_abnormal)
else:
    summary["best_threshold"] = "N/A"
    summary["good_threshold"] = "N/A"
    summary["bad_threshold"] = "N/A"

summary_df = pd.DataFrame([summary])
summary_df.to_csv(output_path / 'summary.csv', index=False, encoding='utf-8-sig')
print(f"âœ… ìš”ì•½ í†µê³„ CSV ì €ì¥: {output_path / 'summary.csv'}")

print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜: {output_path}")

