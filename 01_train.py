import warnings
warnings.filterwarnings("ignore")

from pathlib import Path
from anomalib.data.utils import ValSplitMode, TestSplitMode
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import torch
from datetime import datetime
import json

from anomalib.data import Folder
from anomalib.engine import Engine
from anomalib.models import EfficientAd
from anomalib.metrics import AUROC, F1Score, Evaluator
from torchvision.transforms.v2 import Resize

from sklearn.metrics import (
    precision_recall_curve, f1_score, roc_curve, 
    accuracy_score, auc as auc_score
)

import mlflow
import mlflow.pytorch

# ============================================
# 1. ì„¤ì •
# ============================================
DATA_ROOT = "./datasets/MVTecAD/capsule"
TEST_ROOT = "./datasets/MVTecAD/capsule/test"
CATEGORY = "capsule"
RESULTS_DIR = "./results"
MLFLOW_TRACKING_URI = "./mlruns"

# MLflow ì„¤ì •
mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)
mlflow.set_experiment(f"EfficientAD_{CATEGORY}")

# ============================================
# 2. ë°ì´í„°ì…‹ ì„¤ì •
# ============================================
resize_transform = Resize(size=(256, 256))

# í•™ìŠµìš© ë°ì´í„°ì…‹: ì–‘í’ˆ(good)ë§Œ ì‚¬ìš©
train_datamodule = Folder(
    name=f"{CATEGORY}",
    root=DATA_ROOT,
    normal_dir="train/good",
    train_batch_size=1,
    eval_batch_size=1,
    num_workers=0,
    augmentations=resize_transform,
    # val_split_ratio=0,  # Validation split ì—†ìŒ
    test_split_mode=TestSplitMode.NONE,
    val_split_mode=ValSplitMode.SYNTHETIC,
    val_split_ratio=0.25,
)

train_datamodule.setup()
print(f"âœ… í•™ìŠµ ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!")
print(f"   - í•™ìŠµìš© ì–‘í’ˆ ì´ë¯¸ì§€: {len(train_datamodule.train_dataloader().dataset)}ê°œ")

# Threshold/í‰ê°€ìš© ë°ì´í„°ì…‹: test ì „ì²´ (good + defects)
# TEST_ROOT ì „ì²´ë¥¼ testë¡œ ì‚¬ìš©í•˜ê³ , valì€ testì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
test_datamodule = Folder(
    name=f"{CATEGORY}_test",
    root=TEST_ROOT,          # ./capsule/test
    normal_dir="good",
    normal_test_dir="good",
    abnormal_dir=[
        "crack",
        "faulty_imprint",
        "poke",
        "scratch",
        "squeeze",
    ],
    train_batch_size=1,
    eval_batch_size=1,
    num_workers=0,
    augmentations=resize_transform,
    test_split_mode=TestSplitMode.FROM_DIR,   # TEST_ROOT ì „ì²´ë¥¼ testë¡œ ì‚¬ìš©
    val_split_mode=ValSplitMode.SAME_AS_TEST,    # testì—ì„œ val ë¶„ë¦¬ (í•˜ì§€ë§Œ ratio=0ì´ë¯€ë¡œ ë™ì¼)
    seed=42,
)

test_datamodule.setup()

# ì‹¤ì œ íŒŒì¼ ê°œìˆ˜ì™€ dataset ê°œìˆ˜ ë¹„êµ
all_png = list(Path(TEST_ROOT).rglob("*.png"))
# test_dataloader ì‚¬ìš© (TEST_ROOT ì „ì²´ê°€ testë¡œ ì„¤ì •ë¨)
test_dataloader = test_datamodule.test_dataloader()
test_dataset = test_dataloader.dataset

print("âœ… Threshold/í‰ê°€ìš© ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ!")
print(f"   - ì‹¤ì œ png íŒŒì¼ ê°œìˆ˜ (TEST_ROOT): {len(all_png)}")
print(f"   - test_dataset í¬ê¸°             : {len(test_dataset)}ê°œ ì´ë¯¸ì§€")
print(f"   - test ë°°ì¹˜ ìˆ˜                  : {len(test_dataloader)}ê°œ ë°°ì¹˜")
if len(test_dataset) < len(all_png):
    print(f"   âš ï¸ ê²½ê³ : ë°ì´í„°ì…‹ í¬ê¸°({len(test_dataset)})ê°€ ì‹¤ì œ íŒŒì¼ ìˆ˜({len(all_png)})ë³´ë‹¤ ì ìŠµë‹ˆë‹¤!")
    print(f"      ì°¨ì´: {len(all_png) - len(test_dataset)}ê°œ íŒŒì¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   ğŸ’¡ ë””ë²„ê¹…: test_datamodule êµ¬ì¡° í™•ì¸ ì¤‘...")
    if hasattr(test_datamodule, 'test_set'):
        print(f"      - test_set í¬ê¸°: {len(test_datamodule.test_set) if hasattr(test_datamodule.test_set, '__len__') else 'N/A'}")
else:
    print(f"   âœ… ëª¨ë“  ì´ë¯¸ì§€ê°€ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤!")

# ============================================
# 3. ëª¨ë¸ ì„¤ì •
# ============================================
test_metrics = [
    AUROC(fields=["pred_score", "gt_label"], prefix="image_"),
    F1Score(fields=["pred_label", "gt_label"], prefix="image_"),
]
evaluator = Evaluator(test_metrics=test_metrics)

pre_processor = EfficientAd.configure_pre_processor(image_size=(256, 256))

model = EfficientAd(
    teacher_out_channels=384,
    model_size="small",
    lr=0.0001,
    weight_decay=0.00001,
    padding=False,
    pad_maps=False,
    evaluator=evaluator,
    pre_processor=pre_processor,
)

# ============================================
# 4. í•™ìŠµ ì—”ì§„ ì„¤ì •
# ============================================
epochs = 5

engine = Engine(
    max_epochs=epochs,
    accelerator="auto",
    devices=1,
    default_root_dir=RESULTS_DIR,
)

# ============================================
# 5. MLflow í•™ìŠµ ì‹œì‘
# ============================================
# ëª¨ë¸ ë²„ì „ í™•ì¸ (í•™ìŠµ ì „ ê¸°ì¡´ ë²„ì „ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë²„ì „ ì˜ˆì¸¡)
results_path = Path(RESULTS_DIR) / "EfficientAd" / CATEGORY
next_version = 0
if results_path.exists():
    versions = [d for d in results_path.iterdir() if d.is_dir() and d.name.startswith('v')]
    if versions:
        # ê¸°ì¡´ ë²„ì „ ì¤‘ ìµœëŒ€ê°’ ì°¾ê¸°
        version_numbers = [int(v.name[1:]) for v in versions if v.name[1:].isdigit()]
        if version_numbers:
            next_version = max(version_numbers) + 1
        else:
            next_version = 1
    else:
        next_version = 0
else:
    next_version = 0

# íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (í•™ìŠµ ì „ì— ìƒì„±í•˜ì—¬ ì¼ê´€ì„± ìœ ì§€)
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

# Run name ìƒì„±: ì œí’ˆëª…_ëª¨ë¸ë²„ì „_ë…„ì›”ì¼_ì‹œë¶„ì´ˆ
# ì£¼ì˜: í•™ìŠµ í›„ ì‹¤ì œ ë²„ì „ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•™ìŠµ í›„ í™•ì¸ í•„ìš”
run_name = f"{CATEGORY}_v{next_version}_{timestamp}"

print(f"ğŸ“ MLflow Run Name: {run_name}")
print(f"ğŸ“¦ ì˜ˆìƒ ëª¨ë¸ ë²„ì „: v{next_version}")
print(f"â° íƒ€ì„ìŠ¤íƒ¬í”„: {timestamp}")

with mlflow.start_run(run_name=run_name):
    # ì˜ˆìƒ ë²„ì „ì„ íƒœê·¸ë¡œ ì €ì¥
    mlflow.set_tag("expected_version", f"v{next_version}")
    mlflow.set_tag("timestamp", timestamp)
    # í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
    mlflow.log_params({
        "model": "EfficientAD",
        "category": CATEGORY,
        "model_size": "small",
        "lr": 0.0001,
        "weight_decay": 0.00001,
        "max_epochs": epochs,
        "image_size": "256x256",
    })
    
    # ëª¨ë¸ í•™ìŠµ (ì–‘í’ˆë§Œ ì‚¬ìš©)
    print("ğŸš€ ëª¨ë¸ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì–‘í’ˆ ë°ì´í„°ë§Œ ì‚¬ìš©)")
    engine.fit(datamodule=train_datamodule, model=model)
    
    # í•™ìŠµ í›„ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ì°¾ê¸°
    results_path = Path(RESULTS_DIR) / "EfficientAd" / CATEGORY
    versions = [d for d in results_path.iterdir() if d.is_dir() and d.name.startswith('v')]
    if versions:
        latest_version = max(versions, key=lambda x: int(x.name[1:]) if x.name[1:].isdigit() else 0)
        actual_version = latest_version.name  # v0, v1, v2 ë“±
        actual_version_num = int(actual_version[1:]) if actual_version[1:].isdigit() else 0
        
        # ì‹¤ì œ ë²„ì „ì„ íƒœê·¸ë¡œ ì €ì¥
        mlflow.set_tag("model_version", actual_version)
        mlflow.set_tag("model_version_number", str(actual_version_num))
        mlflow.set_tag("actual_version", actual_version)  # ëª…í™•í•œ íƒœê·¸
        
        ckpt_path = latest_version / "weights" / "lightning" / "model.ckpt"
        if not ckpt_path.exists():
            ckpt_path = list(latest_version.glob("**/model.ckpt"))[0]
        
        # ì²´í¬í¬ì¸íŠ¸ë¥¼ artifactë¡œ ì €ì¥
        mlflow.log_artifact(str(ckpt_path), "checkpoints")
        print(f"ğŸ’¾ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {ckpt_path}")
        print(f"ğŸ“¦ ì‹¤ì œ ëª¨ë¸ ë²„ì „: {actual_version}")
        
        # ì˜ˆìƒ ë²„ì „ê³¼ ì‹¤ì œ ë²„ì „ ë¹„êµ ë° ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
        if actual_version_num != next_version:
            print(f"\nâš ï¸ ê²½ê³ : ì˜ˆìƒ ë²„ì „(v{next_version})ê³¼ ì‹¤ì œ ë²„ì „({actual_version})ì´ ë‹¤ë¦…ë‹ˆë‹¤!")
            print(f"   - MLflow Run Name: {run_name}")
            print(f"   - ì‹¤ì œ ëª¨ë¸ ë²„ì „: {actual_version}")
            print(f"   - MLflowì—ì„œ 'actual_version' íƒœê·¸ë¡œ ì‹¤ì œ ë²„ì „ì„ í™•ì¸í•˜ì„¸ìš”.")
            mlflow.set_tag("version_mismatch", "true")
            mlflow.set_tag("version_mismatch_info", f"expected_v{next_version}_actual_{actual_version}")
        else:
            print(f"âœ… ë²„ì „ ì¼ì¹˜ í™•ì¸: ì˜ˆìƒ ë²„ì „(v{next_version})ê³¼ ì‹¤ì œ ë²„ì „({actual_version})ì´ ì¼ì¹˜í•©ë‹ˆë‹¤.")
            mlflow.set_tag("version_mismatch", "false")
    
    # ëª¨ë¸ í‰ê°€ (Test ë°ì´í„°ì…‹ìœ¼ë¡œ)
    print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘... (Test ë°ì´í„°ì…‹ ì‚¬ìš©)")
    test_results = engine.test(datamodule=test_datamodule, model=model)
    
    # í‰ê°€ ê²°ê³¼ ë¡œê¹…
    for result in test_results:
        for key, value in result.items():
            mlflow.log_metric(key, value)
    
    # ============================================
    # 6. Test ì…‹ ì „ì²´ ì˜ˆì¸¡ ë° Threshold ê³„ì‚°
    # ============================================
    print("ğŸ” Test ì…‹ ì „ì²´ ì˜ˆì¸¡ ì¤‘... (Threshold ê³„ì‚°ìš©)")
    predictions = engine.predict(model=model, datamodule=test_datamodule)
    
    print(f"âœ… ì˜ˆì¸¡ ì™„ë£Œ! ì´ {len(predictions)} ë°°ì¹˜")
    
    # ì˜ˆì¸¡ ê²°ê³¼ ìˆ˜ì§‘
    y_test = []
    y_scores = []
    paths = []
    anomaly_images = []  # ë¶ˆëŸ‰ìœ¼ë¡œ íŒë‹¨í•œ ì´ë¯¸ì§€ë“¤
    total_processed = 0
    
    def extract_defect_type(image_path: str) -> str:
        """ì´ë¯¸ì§€ ê²½ë¡œì—ì„œ ë¶ˆëŸ‰ ìœ í˜• ì¶”ì¶œ"""
        if image_path is None:
            return "unknown"
        path_str = str(image_path).replace("\\", "/")
        if "/test/crack" in path_str or "/crack/" in path_str:
            return "crack"
        elif "/test/faulty_imprint" in path_str or "/faulty_imprint/" in path_str:
            return "faulty_imprint"
        elif "/test/poke" in path_str or "/poke/" in path_str:
            return "poke"
        elif "/test/scratch" in path_str or "/scratch/" in path_str:
            return "scratch"
        elif "/test/squeeze" in path_str or "/squeeze/" in path_str:
            return "squeeze"
        elif "/test/good" in path_str or "/train/good" in path_str or "/good/" in path_str:
            return "good"
        else:
            return "unknown"
    
    for batch in predictions:
        batch_size = batch.image.shape[0]
        for i in range(batch_size):
            total_processed += 1
            image_path = batch.image_path[i] if hasattr(batch, 'image_path') else None
            gt_label = batch.gt_label[i].item() if hasattr(batch, 'gt_label') else None
            pred_score = batch.pred_score[i].item() if hasattr(batch, 'pred_score') else None
            pred_label = batch.pred_label[i].item() if hasattr(batch, 'pred_label') else None
            
            if gt_label is not None and pred_score is not None:
                y_test.append(int(gt_label))
                y_scores.append(float(pred_score))
                paths.append(str(image_path) if image_path else f"unknown_{i}")
                
                # ë¶ˆëŸ‰ìœ¼ë¡œ íŒë‹¨í•œ ì´ë¯¸ì§€ ì €ì¥ (pred_label == 1, good í¬í•¨)
                if pred_label == 1:
                    defect_type = extract_defect_type(image_path)
                    img = batch.image[i].permute(1, 2, 0).cpu().numpy()
                    img = (img - img.min()) / (img.max() - img.min() + 1e-8)
                    img = (img * 255).astype(np.uint8)
                    
                    # Anomaly mapì´ ìˆìœ¼ë©´ ì˜¤ë²„ë ˆì´
                    if hasattr(batch, 'anomaly_map') and batch.anomaly_map is not None:
                        anomaly_map = batch.anomaly_map[i].squeeze().cpu().numpy()
                        anomaly_map = (anomaly_map - anomaly_map.min()) / (anomaly_map.max() - anomaly_map.min() + 1e-8)
                        
                        fig, axes = plt.subplots(1, 3, figsize=(12, 4))
                        axes[0].imshow(img)
                        axes[0].set_title(f"Original\nScore: {pred_score:.3f}")
                        axes[0].axis('off')
                        
                        axes[1].imshow(anomaly_map, cmap='hot')
                        axes[1].set_title("Anomaly Map")
                        axes[1].axis('off')
                        
                        axes[2].imshow(img)
                        axes[2].imshow(anomaly_map, cmap='hot', alpha=0.5)
                        axes[2].set_title("Overlay")
                        axes[2].axis('off')
                        
                        plt.tight_layout()
                        img_name = Path(image_path).stem if image_path else f"unknown_{i}"
                        # ë¶ˆëŸ‰ ìœ í˜•ë³„ í´ë”ë¡œ ì €ì¥
                        save_path = f"anomaly_images/{defect_type}/{img_name}.png"
                        Path(save_path).parent.mkdir(parents=True, exist_ok=True)
                        plt.savefig(save_path, dpi=150, bbox_inches='tight')
                        plt.close()
                        
                        anomaly_images.append(save_path)
    
    # ============================================
    # 7. Threshold ê³„ì‚° í•¨ìˆ˜
    # ============================================
    def calculateThreshold(y_test: list, y_scores: list, path: list) -> tuple:
        """ì–‘í’ˆ, ë¶ˆëŸ‰ì„ ê²°ì •í•˜ëŠ” threshold valueë¥¼ ê²°ì •í•˜ëŠ” í•¨ìˆ˜"""
        if 0 not in y_test:
            return None, None, None, None, None, None
        
        y_test = np.array(y_test)
        y_scores = np.array(y_scores)
        
        # Precision-Recall curveë¡œ threshold í›„ë³´ ì°¾ê¸°
        # anomalib: ì–‘í’ˆ=0, ë¶ˆëŸ‰=1, ë†’ì€ score=ë¹„ì •ìƒ
        # pos_label=1: ë¶ˆëŸ‰ì´ positive class
        thresholds = precision_recall_curve(y_test, y_scores, pos_label=1)[2]
        
        # F1 ìŠ¤ì½”ì–´ë¥¼ ìµœëŒ€í™”í•˜ëŠ” threshold ê°’ ì°¾ê¸°
        # anomalib: ì–‘í’ˆ=0, ë¶ˆëŸ‰=1, ë†’ì€ score=ë¹„ì •ìƒ
        # ë”°ë¼ì„œ score >= thresholdë©´ ë¹„ì •ìƒ(1), score < thresholdë©´ ì •ìƒ(0)
        f1Scores = [f1_score(y_test, (y_scores >= threshold).astype(int), pos_label=1) for threshold in thresholds]
        threshold = thresholds[np.argmax(f1Scores)]
        
        # AUROC ê³„ì‚° (pos_label=1: ë¶ˆëŸ‰ì´ positive class)
        fpr, tpr = roc_curve(y_true=y_test, y_score=y_scores, pos_label=1)[:2]
        auc = auc_score(fpr, tpr) * 100
        
        # DataFrame ìƒì„± (ì´ˆê¸° thresholdë¡œ ì˜ˆì¸¡ ê²°ê³¼ í¬í•¨)
        productTrue = ["OK" if i == 0 else "NG" for i in y_test]
        productPred = ["OK" if score < threshold else "NG" for score in y_scores]
        thresholdDf = pd.DataFrame({
            "product_true": productTrue,
            "product_pred": productPred,
            "y_scores": y_scores
        })
        
        # Good threshold: ì‹¤ì œ ì •ìƒì´ê³  ì˜ˆì¸¡ë„ ì •ìƒì¸ ìƒ˜í”Œë“¤ì˜ ìµœëŒ€ anomaly score
        # (ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ì •ìƒ ìƒ˜í”Œë§Œ ê³ ë ¤)
        goodDf = thresholdDf[(thresholdDf['product_true'] == 'OK') & (thresholdDf['product_pred'] == 'OK')]
        goodThreshold = goodDf["y_scores"].max() if len(goodDf) > 0 else None
        
        # Bad threshold: ì‹¤ì œ ë¶ˆëŸ‰ì´ê³  ì˜ˆì¸¡ë„ ë¶ˆëŸ‰ì¸ ìƒ˜í”Œë“¤ì˜ ìµœì†Œ anomaly score
        # (ëª¨ë¸ì´ ì˜¬ë°”ë¥´ê²Œ ì˜ˆì¸¡í•œ ë¶ˆëŸ‰ ìƒ˜í”Œë§Œ ê³ ë ¤)
        badDf = thresholdDf[(thresholdDf['product_true'] == 'NG') & (thresholdDf['product_pred'] == 'NG')]
        badThreshold = badDf["y_scores"].min() if len(badDf) > 0 else None
        
        # Best threshold: goodê³¼ badì˜ í‰ê· ìœ¼ë¡œ ì‚°ì •
        if goodThreshold is not None and badThreshold is not None:
            bestThreshold = (goodThreshold + badThreshold) / 2
        elif goodThreshold is not None:
            # goodë§Œ ìˆëŠ” ê²½ìš°
            bestThreshold = goodThreshold
        elif badThreshold is not None:
            # badë§Œ ìˆëŠ” ê²½ìš°
            bestThreshold = badThreshold
        else:
            # ë‘˜ ë‹¤ ì—†ëŠ” ê²½ìš° fallback
            bestThreshold = threshold
        
        # Accuracy ê³„ì‚°
        # anomalib: ì–‘í’ˆ=0, ë¶ˆëŸ‰=1, ë†’ì€ score=ë¹„ì •ìƒ
        # ë”°ë¼ì„œ score >= thresholdë©´ ë¹„ì •ìƒ(1), score < thresholdë©´ ì •ìƒ(0)
        y_pred = [1 if i >= bestThreshold else 0 for i in y_scores]
        accuracy = accuracy_score(y_true=y_test, y_pred=y_pred) * 100
        
        return bestThreshold, goodThreshold, badThreshold, accuracy, auc, threshold
    
    # Threshold ê³„ì‚°
    bestThreshold, goodThreshold, badThreshold, accuracy, auc, initial_threshold = calculateThreshold(
        y_test, y_scores, paths
    )
    
    if bestThreshold is not None:
        # ============================================
        # ëª¨ë¸ ë‚´ë¶€ ì†ì„±ìœ¼ë¡œ threshold ì €ì¥
        # ============================================
        # register_bufferë¥¼ ì‚¬ìš©í•˜ì—¬ state_dictì— í¬í•¨ (ëª¨ë¸ ì €ì¥ ì‹œ í•¨ê»˜ ì €ì¥ë¨)
        model.register_buffer("best_threshold", torch.tensor(bestThreshold, dtype=torch.float32))
        if goodThreshold is not None:
            model.register_buffer("good_threshold", torch.tensor(goodThreshold, dtype=torch.float32))
        else:
            model.register_buffer("good_threshold", torch.tensor(0.0, dtype=torch.float32))
        
        if badThreshold is not None:
            model.register_buffer("bad_threshold", torch.tensor(badThreshold, dtype=torch.float32))
        else:
            model.register_buffer("bad_threshold", torch.tensor(0.0, dtype=torch.float32))
        
        # ì¶”ê°€ ë©”íƒ€ë°ì´í„°ë¥¼ ëª¨ë¸ ì†ì„±ìœ¼ë¡œ ì €ì¥ (state_dictì—ëŠ” í¬í•¨ë˜ì§€ ì•Šì§€ë§Œ ëª¨ë¸ ê°ì²´ì— ì €ì¥ë¨)
        model.threshold_accuracy = float(accuracy)
        model.threshold_auc = float(auc)
        model.threshold_category = CATEGORY
        model.initial_threshold = float(initial_threshold)
        
        print(f"âœ… Thresholdë¥¼ ëª¨ë¸ ì†ì„±ìœ¼ë¡œ ì €ì¥ ì™„ë£Œ:")
        print(f"  - best_threshold: {bestThreshold:.4f}")
        print(f"  - good_threshold: {goodThreshold:.4f}" if goodThreshold is not None else "  - good_threshold: None")
        print(f"  - bad_threshold: {badThreshold:.4f}" if badThreshold is not None else "  - bad_threshold: None")
        
        # Threshold ê´€ë ¨ ë©”íŠ¸ë¦­ ë¡œê¹…
        mlflow.log_metrics({
            "best_threshold": bestThreshold,
            "good_threshold": goodThreshold if goodThreshold is not None else 0.0,
            "bad_threshold": badThreshold if badThreshold is not None else 0.0,
            "threshold_accuracy": accuracy,
            "threshold_auc": auc,
        })
        
        # Threshold ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ëª¨ë¸ ì €ì¥ ê²½ë¡œì— í•¨ê»˜ ì €ì¥)
        threshold_info = {
            "best_threshold": float(bestThreshold),
            "good_threshold": float(goodThreshold) if goodThreshold is not None else None,
            "bad_threshold": float(badThreshold) if badThreshold is not None else None,
            "threshold_accuracy": float(accuracy),
            "threshold_auc": float(auc),
            "initial_threshold": float(initial_threshold),
            "category": CATEGORY,
            "model_name": "EfficientAD",
        }
        
        # ëª¨ë¸ ì €ì¥ ê²½ë¡œì— threshold_info.json ì €ì¥
        if versions:
            threshold_json_path = latest_version / "threshold_info.json"
            with open(threshold_json_path, "w", encoding="utf-8") as f:
                json.dump(threshold_info, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ Threshold ì •ë³´ ì €ì¥: {threshold_json_path}")
        
        # MLflowì—ë„ artifactë¡œ ì €ì¥
        with open("threshold_info.json", "w", encoding="utf-8") as f:
            json.dump(threshold_info, f, indent=2, ensure_ascii=False)
        mlflow.log_artifact("threshold_info.json")
        
        # ì˜ˆì¸¡ ê²°ê³¼ DataFrame ì €ì¥
        # anomalib: ì–‘í’ˆ=0, ë¶ˆëŸ‰=1, ë†’ì€ score=ë¹„ì •ìƒ
        # ë”°ë¼ì„œ score >= thresholdë©´ ë¹„ì •ìƒ(1), score < thresholdë©´ ì •ìƒ(0)
        df = pd.DataFrame({
            "image_path": paths,
            "gt_label": y_test,
            "pred_score": y_scores,
            "pred_label": [1 if score >= bestThreshold else 0 for score in y_scores],
        })
        df.to_csv("predictions.csv", index=False, encoding='utf-8-sig')
        mlflow.log_artifact("predictions.csv")
    
    # ============================================
    # 8. ë¶ˆëŸ‰ ì´ë¯¸ì§€ë“¤ì„ Artifactë¡œ ì €ì¥ (ë¶ˆëŸ‰ ìœ í˜•ë³„ í´ë” êµ¬ì¡° ìœ ì§€)
    # ============================================
    if anomaly_images:
        # anomaly_images í´ë” ì „ì²´ë¥¼ artifactë¡œ ì €ì¥ (ë¶ˆëŸ‰ ìœ í˜•ë³„ í´ë” êµ¬ì¡° ìœ ì§€)
        mlflow.log_artifacts("anomaly_images", "anomaly_segmentation")
    
    # ëª¨ë¸ ì €ì¥ (threshold ì •ë³´ì™€ í•¨ê»˜)
    from mlflow.models import infer_signature
    
    # Signature ìƒì„±ìš© ìƒ˜í”Œ ë°ì´í„°
    sample_batch = next(iter(test_datamodule.test_dataloader()))
    sample_input = sample_batch["image"][:1]  # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ
    
    # ëª¨ë¸ì„ eval ëª¨ë“œë¡œ ì„¤ì •í•˜ê³  ì˜ˆì¸¡
    model.eval()
    with torch.no_grad():
        sample_output = model(sample_input)
    
    # Signature ì¶”ë¡  (outputì´ dictì¸ ê²½ìš° ì²˜ë¦¬)
    if isinstance(sample_output, dict):
        output_data = sample_output.get("pred_score", sample_output.get("anomaly_map", list(sample_output.values())[0]))
        if hasattr(output_data, "numpy"):
            output_data = output_data.numpy()
    else:
        output_data = sample_output.numpy() if hasattr(sample_output, "numpy") else sample_output
    
    signature = infer_signature(sample_input.numpy(), output_data)
    
    # Threshold ì •ë³´ë¥¼ íƒœê·¸ë¡œ ì €ì¥ (ëª¨ë¸ê³¼ í•¨ê»˜ ì¶”ì  ê°€ëŠ¥)
    if bestThreshold is not None:
        mlflow.set_tag("best_threshold", str(bestThreshold))
        if goodThreshold is not None:
            mlflow.set_tag("good_threshold", str(goodThreshold))
        if badThreshold is not None:
            mlflow.set_tag("bad_threshold", str(badThreshold))
        mlflow.set_tag("threshold_category", CATEGORY)
    
    # ëª¨ë¸ ì €ì¥ (signatureì™€ input_example í¬í•¨)
    mlflow.pytorch.log_model(
        pytorch_model=model,
        artifact_path="model",
        signature=signature,
        input_example=sample_input.numpy(),
    )
    
    # ëª¨ë¸ ë‚´ë¶€ threshold ì†ì„± í™•ì¸
    if bestThreshold is not None:
        print("\nğŸ“Š ëª¨ë¸ ë‚´ë¶€ threshold ì†ì„± í™•ì¸:")
        print(f"  - model.best_threshold: {model.best_threshold.item():.4f}")
        print(f"  - model.good_threshold: {model.good_threshold.item():.4f}")
        print(f"  - model.bad_threshold: {model.bad_threshold.item():.4f}")
        print(f"  - model.threshold_accuracy: {model.threshold_accuracy:.2f}%")
        print(f"  - model.threshold_auc: {model.threshold_auc:.2f}%")
        print(f"  - model.threshold_category: {model.threshold_category}")
        print("\nğŸ’¡ ëª¨ë¸ ë¡œë“œ ì‹œ threshold ì‚¬ìš© ë°©ë²•:")
        print("  loaded_model = mlflow.pytorch.load_model(model_uri)")
        print("  threshold = loaded_model.best_threshold.item()")
        print("  # ë˜ëŠ”")
        print("  threshold = loaded_model.best_threshold.cpu().numpy()")
    
    print("\nâœ… MLflow ë¡œê¹… ì™„ë£Œ!")

print("ğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
